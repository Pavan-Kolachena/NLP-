{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Import the Libraries"
      ],
      "metadata": {
        "id": "GstmMHrn4Tez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "iQOmd4Dv4Sp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Download the Required Nltk Data"
      ],
      "metadata": {
        "id": "sFwSI2Zk42WH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTD22iJk49rl",
        "outputId": "3163bb7c-e6de-40d4-d9a1-92054fdddb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Sample text"
      ],
      "metadata": {
        "id": "wJ9Ja7xX5ID7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"The runner's running shoes are out of tread.\""
      ],
      "metadata": {
        "id": "ojFU7Meo5KDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#tokenize the text"
      ],
      "metadata": {
        "id": "XmTfKWeR5Vg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens=word_tokenize(text)"
      ],
      "metadata": {
        "id": "WlXQvZH15ZBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#stemming\n"
      ],
      "metadata": {
        "id": "A9xJBmuM5gjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer=PorterStemmer()\n",
        "stemmed_words=[stemmer.stem(word)for word in tokens]"
      ],
      "metadata": {
        "id": "TCIWL-MW5jqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#lemmatization"
      ],
      "metadata": {
        "id": "UMcDM-bz58AK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize=WordNetLemmatizer()\n",
        "lemmatized_words=[lemmatize.lemmatize(word)for word in tokens]"
      ],
      "metadata": {
        "id": "pmsE1GYB5-dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print the results"
      ],
      "metadata": {
        "id": "ViYqMeoi6U__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Text:\",text)\n",
        "print(\"\\nTokens:\",tokens)\n",
        "print(\"\\nStemmed Words:\",stemmed_words)\n",
        "print(\"\\nLemmatized Words:\",lemmatized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoJ42AWS6bKt",
        "outputId": "be4014c1-dede-4949-b670-b8ec6530a44f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text: The runner's running shoes are out of tread.\n",
            "\n",
            "Tokens: ['The', 'runner', \"'s\", 'running', 'shoes', 'are', 'out', 'of', 'tread', '.']\n",
            "\n",
            "Stemmed Words: ['the', 'runner', \"'s\", 'run', 'shoe', 'are', 'out', 'of', 'tread', '.']\n",
            "\n",
            "Lemmatized Words: ['The', 'runner', \"'s\", 'running', 'shoe', 'are', 'out', 'of', 'tread', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part of speech tagging"
      ],
      "metadata": {
        "id": "ULa8NYhq7Bus"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bQglEKZ7D-E",
        "outputId": "b4f2c58e-aa1f-4a10-d40d-deaa58c5c221"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Helper function to get nltk pos tagsto wordnet pos tags"
      ],
      "metadata": {
        "id": "2VWGbQ9Q7Nq8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordnet_pos(tag):\n",
        "  tag= tag[0].upper()\n",
        "  tag_dict={\"J\":nltk.corpus.wordnet.ADJ,\n",
        "            \"N\":nltk.corpus.wordnet.NOUN,\n",
        "            \"V\":nltk.corpus.wordnet.VERB,\n",
        "            \"R\":nltk.corpus.wordnet.ADV}\n",
        "  return tag_dict.get(tag,nltk.corpus.wordnet.NOUN)"
      ],
      "metadata": {
        "id": "INWV9rSU7VOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"J\",nltk.corpus.wordnet.ADJ)\n",
        "print(\"N\",nltk.corpus.wordnet.NOUN)\n",
        "print(\"V\",nltk.corpus.wordnet.VERB)\n",
        "print(\"R\",nltk.corpus.wordnet.ADV)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRSVV7Hc8EnV",
        "outputId": "6df2358e-b40a-4c6e-d5b0-03fdd9cd2795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "J a\n",
            "N n\n",
            "V v\n",
            "R r\n"
          ]
        }
      ]
    }
  ]
}